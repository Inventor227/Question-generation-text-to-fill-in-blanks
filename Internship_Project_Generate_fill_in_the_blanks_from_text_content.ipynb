{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhv20N4TepLA"
      },
      "source": [
        "## Generate fill in the blanks from any content"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POUBDBDm_cq2"
      },
      "source": [
        "# Installing from https://github.com/boudinfl/pke library for Python Keyword extraction\n",
        "# We use a fixed commit as the later changes might break the code. If it was on pip we would have used exact version number.\n",
        "\n",
        "!pip install --quiet flashtext==2.7\n",
        "!pip install git+https://github.com/boudinfl/pke.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install spacy==2.2.4\n",
        "# !python3 -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "0Z2XnYJvKfca"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scipy==1.8.0\n",
        "!pip install networkx==2.6"
      ],
      "metadata": {
        "id": "guCecRUUnvce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy info"
      ],
      "metadata": {
        "id": "ZKagcStxKJP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ix4g8UhMLX4Q"
      },
      "source": [
        "import textwrap\n",
        "text = \"\"\"There is a lot of volcanic activity at divergent plate boundaries in the oceans. For example, many undersea volcanoes are found along the Mid-Atlantic Ridge. This is a divergent plate boundary that runs north-south through the middle of the Atlantic Ocean. As tectonic plates pull away from each other at a divergent plate boundary, they create deep fissures, or cracks, in the crust. Molten rock, called magma, erupts through these cracks onto Earth’s surface. At the surface, the molten rock is called lava. It cools and hardens, forming rock. Divergent plate boundaries also occur in the continental crust. Volcanoes form at these boundaries, but less often than in ocean crust. That’s because continental crust is thicker than oceanic crust. This makes it more difficult for molten rock to push up through the crust. Many volcanoes form along convergent plate boundaries where one tectonic plate is pulled down beneath another at a subduction zone. The leading edge of the plate melts as it is pulled into the mantle, forming magma that erupts as volcanoes. When a line of volcanoes forms along a subduction zone, they make up a volcanic arc. The edges of the Pacific plate are long subduction zones lined with volcanoes. This is why the Pacific rim is called the “Pacific Ring of Fire.”\"\"\"\n",
        "text= \"\"\"Once, there was a boy who became bored when he watched over the village sheep grazing on the hillside. To entertain himself, he sang out, “Wolf! Wolf! The wolf is chasing the sheep!”\n",
        "\n",
        "When the villagers heard the cry, they came running up the hill to drive the wolf away. But, when they arrived, they saw no wolf. The boy was amused when seeing their angry faces.\n",
        "\n",
        "“Don’t scream wolf, boy,” warned the villagers, “when there is no wolf!” They angrily went back down the hill.\n",
        "\n",
        "Later, the shepherd boy cried out once again, “Wolf! Wolf! The wolf is chasing the sheep!” To his amusement, he looked on as the villagers came running up the hill to scare the wolf away.\n",
        "\n",
        "As they saw there was no wolf, they said strictly, “Save your frightened cry for when there really is a wolf! Don’t cry ‘wolf’ when there is no wolf!” But the boy grinned at their words while they walked grumbling down the hill once more.\n",
        "\n",
        "Later, the boy saw a real wolf sneaking around his flock. Alarmed, he jumped on his feet and cried out as loud as he could, “Wolf! Wolf!” But the villagers thought he was fooling them again, and so they didn’t come to help.\"\"\"\n",
        "wrapper = textwrap.TextWrapper(width=150)\n",
        "word_list = wrapper.wrap(text=text)\n",
        "for element in word_list:\n",
        "  print(element)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guTJJvfWKRbt"
      },
      "source": [
        "import json\n",
        "import requests\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "import string\n",
        "import itertools\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "import pke\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "import traceback\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from flashtext import KeywordProcessor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bn9OEtyuPbk1",
        "outputId": "34f8a203-afba-4180-dcd4-4855ff317596"
      },
      "source": [
        "def tokenize_sentences(text):\n",
        "    sentences = sent_tokenize(text)\n",
        "    sentences = [sentence.strip() for sentence in sentences if len(sentence) > 20]\n",
        "    return sentences\n",
        "\n",
        "sentences = tokenize_sentences(text)\n",
        "print (sentences)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Once, there was a boy who became bored when he watched over the village sheep grazing on the hillside.', 'To entertain himself, he sang out, “Wolf!', 'The wolf is chasing the sheep!”\\n\\nWhen the villagers heard the cry, they came running up the hill to drive the wolf away.', 'But, when they arrived, they saw no wolf.', 'The boy was amused when seeing their angry faces.', '“Don’t scream wolf, boy,” warned the villagers, “when there is no wolf!” They angrily went back down the hill.', 'Later, the shepherd boy cried out once again, “Wolf!', 'The wolf is chasing the sheep!” To his amusement, he looked on as the villagers came running up the hill to scare the wolf away.', 'As they saw there was no wolf, they said strictly, “Save your frightened cry for when there really is a wolf!', 'Don’t cry ‘wolf’ when there is no wolf!” But the boy grinned at their words while they walked grumbling down the hill once more.', 'Later, the boy saw a real wolf sneaking around his flock.', 'Alarmed, he jumped on his feet and cried out as loud as he could, “Wolf!', 'Wolf!” But the villagers thought he was fooling them again, and so they didn’t come to help.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wt5YYO1tI8XS"
      },
      "source": [
        "\n",
        "def get_noun_adj_verb(text):\n",
        "    out=[]\n",
        "    try:\n",
        "        extractor = pke.unsupervised.MultipartiteRank()\n",
        "        extractor.load_document(input=text,language='en')\n",
        "        #    not contain punctuation marks or stopwords as candidates.\n",
        "        pos = {'VERB', 'ADJ', 'NOUN'}\n",
        "        stoplist = list(string.punctuation)\n",
        "        stoplist += ['-lrb-', '-rrb-', '-lcb-', '-rcb-', '-lsb-', '-rsb-']\n",
        "        stoplist += stopwords.words('english')\n",
        "        # extractor.candidate_selection(pos=pos, stoplist=stoplist)\n",
        "        extractor.candidate_selection(pos=pos)\n",
        "        # 4. build the Multipartite graph and rank candidates using random walk,\n",
        "        #    alpha controls the weight adjustment mechanism, see TopicRank for\n",
        "        #    threshold/method parameters.\n",
        "        extractor.candidate_weighting(alpha=1.1,\n",
        "                                      threshold=0.75,\n",
        "                                      method='average')\n",
        "        keyphrases = extractor.get_n_best(n=30)\n",
        "\n",
        "\n",
        "        for val in keyphrases:\n",
        "            out.append(val[0])\n",
        "    except:\n",
        "        out = []\n",
        "        traceback.print_exc()\n",
        "\n",
        "    return out\n",
        "\n",
        "noun_verbs_adj = get_noun_adj_verb(text)\n",
        "print (\"keywords: \",noun_verbs_adj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aXFMFi9cQuBV"
      },
      "source": [
        "from pprint import pprint\n",
        "def get_sentences_for_keyword(keywords, sentences):\n",
        "    keyword_processor = KeywordProcessor()\n",
        "    keyword_sentences = {}\n",
        "    for word in keywords:\n",
        "        keyword_sentences[word] = []\n",
        "        keyword_processor.add_keyword(word)\n",
        "    for sentence in sentences:\n",
        "        keywords_found = keyword_processor.extract_keywords(sentence)\n",
        "        for key in keywords_found:\n",
        "            keyword_sentences[key].append(sentence)\n",
        "\n",
        "    for key in keyword_sentences.keys():\n",
        "        values = keyword_sentences[key]\n",
        "        values = sorted(values, key=len, reverse=True)\n",
        "        keyword_sentences[key] = values\n",
        "    return keyword_sentences\n",
        "\n",
        "keyword_sentence_mapping_noun_verbs_adj = get_sentences_for_keyword(noun_verbs_adj, sentences)\n",
        "pprint (keyword_sentence_mapping_noun_verbs_adj)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTsmxtR0HyCC"
      },
      "source": [
        "\n",
        "def get_fill_in_the_blanks(sentence_mapping):\n",
        "    out={\"title\":\"Fill in the blanks for these sentences with matching words at the top\"}\n",
        "    blank_sentences = []\n",
        "    processed = []\n",
        "    keys=[]\n",
        "    for key in sentence_mapping:\n",
        "        if len(sentence_mapping[key])>0:\n",
        "            sent = sentence_mapping[key][0]\n",
        "            # Compile a regular expression pattern into a regular expression object, which can be used for matching and other methods\n",
        "            insensitive_sent = re.compile(re.escape(key), re.IGNORECASE)\n",
        "            no_of_replacements =  len(re.findall(re.escape(key),sent,re.IGNORECASE))\n",
        "            line = insensitive_sent.sub(' _________ ', sent)\n",
        "            if (sentence_mapping[key][0] not in processed) and no_of_replacements<2:\n",
        "                blank_sentences.append(line)\n",
        "                processed.append(sentence_mapping[key][0])\n",
        "                keys.append(key)\n",
        "    out[\"sentences\"]=blank_sentences[:10]\n",
        "    out[\"keys\"]=keys[:10]\n",
        "    return out\n",
        "\n",
        "\n",
        "fill_in_the_blanks = get_fill_in_the_blanks(keyword_sentence_mapping_noun_verbs_adj)\n",
        "pprint(fill_in_the_blanks)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BgPdoW6wPVH"
      },
      "source": [
        "from IPython.core.display import display, HTML\n",
        "import xml.etree.ElementTree as et\n",
        "import random\n",
        "\n",
        "root = et.Element(\"div\")\n",
        "\n",
        "heading = et.Element(\"h2\")\n",
        "heading.text = fill_in_the_blanks['title']\n",
        "\n",
        "keywords = et.Element(\"ul\")\n",
        "keywords.set('style', 'color:blue;')\n",
        "\n",
        "all_keys = fill_in_the_blanks['keys']\n",
        "random.shuffle(all_keys)\n",
        "for blank in all_keys:\n",
        "  child=et.Element(\"li\")\n",
        "  child.text = blank\n",
        "  keywords.append(child)\n",
        "\n",
        "sentences = et.Element(\"ol\")\n",
        "sentences.set('style', 'color:brown;')\n",
        "for sentence in fill_in_the_blanks['sentences']:\n",
        "  child=et.Element(\"li\")\n",
        "  child.text = sentence\n",
        "  sentences.append(child)\n",
        "  sentences.append(et.Element(\"br\"))\n",
        "\n",
        "heading_content = et.Element(\"h4\")\n",
        "\n",
        "root.append(heading)\n",
        "heading_content.append(keywords)\n",
        "heading_content.append(sentences)\n",
        "root.append(heading_content)\n",
        "\n",
        "xmlstr = et.tostring(root)\n",
        "xmlstr = xmlstr.decode(\"utf-8\")\n",
        "display(HTML(xmlstr))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFogG7KKgf4s"
      },
      "source": [
        "from xml.dom import minidom\n",
        "prettyxmlstr = minidom.parseString(et.tostring(root)).toprettyxml(indent=\"   \")\n",
        "print (prettyxmlstr)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}